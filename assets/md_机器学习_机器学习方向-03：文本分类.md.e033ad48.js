import{_ as s,o as n,c as a,U as l}from"./chunks/framework.5628684b.js";const C=JSON.parse('{"title":"机器学习-03：文本分类任务","description":"","frontmatter":{},"headers":[],"relativePath":"md/机器学习/机器学习方向-03：文本分类.md","filePath":"md/机器学习/机器学习方向-03：文本分类.md"}'),o={name:"md/机器学习/机器学习方向-03：文本分类.md"},p=l(`<p><img src="https://img1.imgtp.com/2023/09/10/081jz2kT.PNG" alt=""></p><h1 id="机器学习-03-文本分类任务" tabindex="-1"><strong>机器学习</strong>-03：文本分类任务 <a class="header-anchor" href="#机器学习-03-文本分类任务" aria-label="Permalink to &quot;**机器学习**-03：文本分类任务&quot;">​</a></h1><blockquote><p><code>难度系数</code>：中等</p><p>在学习了有关梯度下降的知识之后，可以开始尝试深度学习框架了！深度学习框架是用于构建、训练和部署深度学习模型的软件工具。它们提供了一系列的函数、类和工具，使得开发者可以方便地定义、优化和执行深度学习模型。常见的深度学习框架有tensorflow、pytorch、keras等，选择一种框架进行学习，在学习过程中记录下你的思考与体验。</p></blockquote><h2 id="前置知识" tabindex="-1">前置知识 <a class="header-anchor" href="#前置知识" aria-label="Permalink to &quot;前置知识&quot;">​</a></h2><h3 id="nlp前置知识" tabindex="-1">NLP前置知识 <a class="header-anchor" href="#nlp前置知识" aria-label="Permalink to &quot;NLP前置知识&quot;">​</a></h3><p>在理解和应用 RNN 类模型进行文本分类之前，有几个重要的 NLP 前置知识需要了解：</p><blockquote><p><strong>文本分类：</strong> 文本分类是一种自然语言处理（NLP）任务，旨在将给定的文本分配到预定义的类别或标签中。它是根据文本的内容和语义特征来判断文本所属类别的过程。在文本分类任务中，通常有一个已知的类别集合，每个类别代表一个特定的主题、情感或类别。模型的目标是根据文本的特征和上下文信息，将其正确地分类到相应的类别中。</p><p><strong>文本预处理：</strong> 包括文本清洗、分词、去除停用词等，以便将文本数据转化为可供模型处理的形式。</p><p><strong>词嵌入</strong>（Word Embeddings）：将文本中的单词映射为低维的实数向量表示，以捕捉单词之间的语义关系。</p><p><strong>循环神经网络</strong>（Recurrent Neural Networks，RNN）：一种能够处理序列数据的神经网络模型，通过在每个时间步骤上传递隐藏状态，可以捕捉到序列中的上下文信息。</p><p><strong>长短时记忆网络</strong>（Long Short-Term Memory，LSTM）：一种RNN的变体，通过引入门控机制，可以更好地处理长期依赖关系。</p><p><strong>注意⭐️：在本次任务中，我们并不限定任何模型和实现方式。RNN和LSTM不是必须的，推荐使用，还未接触RNN的初学者同学也可以使用MLP模型（是的MLP也是可以用的，只是效果差点，但是我们强烈推荐初学者同学用MLP来一次实践），高阶的同学甚至可以直接上BERT模型</strong></p></blockquote><h3 id="文本处理前置知识" tabindex="-1">文本处理前置知识 <a class="header-anchor" href="#文本处理前置知识" aria-label="Permalink to &quot;文本处理前置知识&quot;">​</a></h3><p>文本处理是指对文本数据进行<strong>预处理和转换</strong>的过程，以便于后续的文本分析、挖掘和建模。文本处理的目标是清洗、规范和转换原始文本数据，以提取有用的信息和特征，从而支持各种文本相关的任务，如文本分类、情感分析、机器翻译等。</p><p>下面是一些常见的文本处理步骤：</p><ol><li>文本清洗：去除文本中的特殊字符、标点符号和HTML标签等无关信息。处理大小写，可以将文本转换为小写形式，以避免同一个单词因大小写不同而被视为不同的词汇。</li></ol><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> re</span></span>
<span class="line"><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">clean_text</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;font-style:italic;">text</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#676E95;font-style:italic;"># 去除特殊字符和标点符号</span></span>
<span class="line"><span style="color:#A6ACCD;">    text </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> re</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">sub</span><span style="color:#89DDFF;">(</span><span style="color:#C792EA;">r</span><span style="color:#89DDFF;">&quot;[^</span><span style="color:#C3E88D;">a-zA-Z0-9</span><span style="color:#89DDFF;">]&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> text</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#676E95;font-style:italic;"># 将文本转换为小写</span></span>
<span class="line"><span style="color:#A6ACCD;">    text </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> text</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">lower</span><span style="color:#89DDFF;">()</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#676E95;font-style:italic;"># 去除多余的空格</span></span>
<span class="line"><span style="color:#A6ACCD;">    text </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> re</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">sub</span><span style="color:#89DDFF;">(</span><span style="color:#C792EA;">r</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">\\s</span><span style="color:#89DDFF;">+&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> text</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;font-style:italic;">return</span><span style="color:#A6ACCD;"> text</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 示例文本</span></span>
<span class="line"><span style="color:#A6ACCD;">text </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">Hello, this is an example text! It contains special characters and punctuation.</span><span style="color:#89DDFF;">&quot;</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 清洗文本</span></span>
<span class="line"><span style="color:#A6ACCD;">cleaned_text </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">clean_text</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">text</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">cleaned_text</span><span style="color:#89DDFF;">)</span></span></code></pre></div><p>在以上代码中，<code>clean_text</code>函数使用正则表达式去除了特殊字符和标点符号，将文本转换为小写，并去除了多余的空格。你可以根据需要进行修改和扩展，例如添加停用词移除、词干提取等其他文本清洗步骤。</p><ol start="2"><li>分词（Tokenization）：将文本分割成单词或子词的序列。</li></ol><div class="language-Python"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> re</span></span>
<span class="line"><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">tokenize</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;font-style:italic;">text</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#676E95;font-style:italic;"># 将文本中的标点符号替换为空格</span></span>
<span class="line"><span style="color:#A6ACCD;">    text </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> re</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">sub</span><span style="color:#89DDFF;">(</span><span style="color:#C792EA;">r</span><span style="color:#89DDFF;">&#39;[^</span><span style="color:#C3E88D;">\\w\\s</span><span style="color:#89DDFF;">]&#39;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;"> </span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> text</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#676E95;font-style:italic;"># 将文本按空格分割成单词列表</span></span>
<span class="line"><span style="color:#A6ACCD;">    tokens </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> text</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">split</span><span style="color:#89DDFF;">()</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;font-style:italic;">return</span><span style="color:#A6ACCD;"> tokens</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 示例文本</span></span>
<span class="line"><span style="color:#A6ACCD;">text </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">This is an example sentence for tokenization.</span><span style="color:#89DDFF;">&quot;</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 分词</span></span>
<span class="line"><span style="color:#A6ACCD;">tokens </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">tokenize</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">text</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">tokens</span><span style="color:#89DDFF;">)</span></span></code></pre></div><ol start="3"><li>去除停用词（Stop Words）：停用词是在文本中频繁出现但通常不携带重要信息的常见词汇，如介词、连词和冠词等。去除停用词可以减少文本的维度，并提高模型的效果。</li></ol><div class="language-Python"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#676E95;font-style:italic;"># 停用词列表</span></span>
<span class="line"><span style="color:#A6ACCD;">stop_words </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">[</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">the</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">is</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">an</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">of</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">]</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 示例文本</span></span>
<span class="line"><span style="color:#A6ACCD;">text </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">This is an example sentence demonstrating the removal of stopwords.</span><span style="color:#89DDFF;">&quot;</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 分词</span></span>
<span class="line"><span style="color:#A6ACCD;">tokens </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> text</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">split</span><span style="color:#89DDFF;">()</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 去除停用词</span></span>
<span class="line"><span style="color:#A6ACCD;">filtered_tokens </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">[</span><span style="color:#A6ACCD;">word </span><span style="color:#89DDFF;font-style:italic;">for</span><span style="color:#A6ACCD;"> word </span><span style="color:#89DDFF;font-style:italic;">in</span><span style="color:#A6ACCD;"> tokens </span><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> word</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">lower</span><span style="color:#89DDFF;">()</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">not</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">in</span><span style="color:#A6ACCD;"> stop_words</span><span style="color:#89DDFF;">]</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 打印结果</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">Original Text:</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">text</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">()</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">Filtered Text:</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;"> </span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">join</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">filtered_tokens</span><span style="color:#89DDFF;">))</span></span></code></pre></div><p>在上述代码中，首先定义了一个停用词列（<code>stop_words</code>），其中包含要去除的常见停用词。定义了一个示例文本（<code>text</code>）。接下来，使用<code>split()</code>方法将文本分割成单词，得到一个单词列表（<code>tokens</code>）。然后，使用列表推导式，遍历分词后的单词列表，并将不在停用词列表中的单词保留下来（使用<code>lower()</code>方法将单词转换为小写进行比较）。最后，使用<code>join()</code>方法将过滤后的单词列表重新组合成一个字符串，并打印结果。</p><p><strong>注意：</strong> 上述代码均为示例，与本题无关，实际在完成本题过程中，需要根据具体任务和数据进行相应的调整和修改。</p><h2 id="题目-情绪分类" tabindex="-1">题目-情绪分类 <a class="header-anchor" href="#题目-情绪分类" aria-label="Permalink to &quot;题目-情绪分类&quot;">​</a></h2><ul><li>本题旨在训练一个文本二分类模型，用以预测每个句子所表达的情绪是正面还是负面</li><li>可以使用 MLP 或者 RNN 类模型等，不强制使用任何模型或实现方法，自由发挥！</li><li>可使用深度学习框架，框架不限，推荐使用 tensorflow2 或 pytorch</li></ul><h2 id="举个栗子🌰" tabindex="-1">举个栗子🌰 <a class="header-anchor" href="#举个栗子🌰" aria-label="Permalink to &quot;举个栗子🌰&quot;">​</a></h2><p><strong>下面是一个使用</strong> <strong>pytorch</strong> <strong>框架+ LSTM 模型的代码示例</strong></p><h3 id="环境配置" tabindex="-1"><strong>环境配置</strong> <a class="header-anchor" href="#环境配置" aria-label="Permalink to &quot;**环境配置**&quot;">​</a></h3><ol><li>安装 Anaconda,学习简单的 conda 命令</li><li>推荐选择 tensorflow 或者 pytorch 框架，则创建相应环境，安装 tensorflow/pytorch，以及 GPU 配置（建议安装，需要电脑有独显）</li></ol><h3 id="数据处理" tabindex="-1"><strong>数据处理</strong> <a class="header-anchor" href="#数据处理" aria-label="Permalink to &quot;**数据处理**&quot;">​</a></h3><ul><li>获取数据集（招新群 683234808）或者从 kaggle 上下载 <a href="https://www.kaggle.com/competitions/ml2020spring-hw4/overview" target="_blank" rel="noreferrer">ML2020spring - hw4 | Kaggle</a></li><li><strong>在该数据集中只会用到 training_label.txt，并且请自行划分训练、验证、测试集</strong></li><li>训练集的每一行为一个数据，每个数据分别包含一个文本和一个 label（0表示消极情绪，1表示积极情绪）</li><li>拿到数据之后，需要对数据进行文本处理（可参考上文），再建立词表，以及做 word2id、label2id 的映射等：</li></ul><div class="language-Python"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">create_corpus</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;font-style:italic;">texts</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;font-style:italic;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">    通过对训练文本做文本处理（参考上文）并统计分词结果，建立词表</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">    小Tips：建立词表的时候别忘了加一些特殊token，如：</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">        [PAD]：用于id序列的padding的token</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">        [UNK]：用于映射不存在于词表的词</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">    请自行实现</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">    </span><span style="color:#89DDFF;font-style:italic;">&quot;&quot;&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">preprocess_text</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;font-style:italic;">text</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;font-style:italic;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">    对数据进行处理，包括文本处理（参考上文）、做word2id映射、id序列的padding等</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">    padding：</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">        由于将不同的文本序列组成一个batch时，需要每个文本的长度相同</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">        所以需要对某些文本进行截断或填充，填充的word即为[PAD]</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">        如：将I love you填充至seq_len=5，即为I love you [PAD] [PAD]</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">    请自行实现</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">    </span><span style="color:#89DDFF;font-style:italic;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span></span>
<span class="line"><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">preprocess_label</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;font-style:italic;">label</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;font-style:italic;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">    包括label2id的映射等</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">    请自行实现</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">    </span><span style="color:#89DDFF;font-style:italic;">&quot;&quot;&quot;</span></span></code></pre></div><h3 id="dataset" tabindex="-1"><strong>Dataset</strong> <a class="header-anchor" href="#dataset" aria-label="Permalink to &quot;**Dataset**&quot;">​</a></h3><ul><li>在pytorch中，需要建立<code>Dataset()</code>定义我们处理数据的方式，其中的<code>__getitem()__</code>即定义了每单个数据的处理方法，之后在训练时再用<code>DataLoader()</code>进行封装，即可组成一个 batch 的数据</li></ul><div class="language-Python"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#C792EA;">class</span><span style="color:#A6ACCD;"> </span><span style="color:#FFCB6B;">CustomDataset</span><span style="color:#89DDFF;">(</span><span style="color:#FFCB6B;">torch</span><span style="color:#89DDFF;">.</span><span style="color:#FFCB6B;">utils</span><span style="color:#89DDFF;">.</span><span style="color:#FFCB6B;">data</span><span style="color:#89DDFF;">.</span><span style="color:#FFCB6B;">Dataset</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">__init__</span><span style="color:#89DDFF;">(</span><span style="color:#F07178;font-style:italic;">self</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">texts</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">labels</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">        self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">texts</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> texts</span></span>
<span class="line"><span style="color:#A6ACCD;">        self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">labels</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> labels</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">__getitem__</span><span style="color:#89DDFF;">(</span><span style="color:#F07178;font-style:italic;">self</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">index</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">        text </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">preprocess_text</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;">self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">texts</span><span style="color:#89DDFF;">[</span><span style="color:#F07178;">index</span><span style="color:#89DDFF;">])</span></span>
<span class="line"><span style="color:#A6ACCD;">        label </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">preprocess_label</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;">self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">labels</span><span style="color:#89DDFF;">[</span><span style="color:#F07178;">index</span><span style="color:#89DDFF;">])</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;font-style:italic;">return</span><span style="color:#A6ACCD;"> text</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> label</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">__len__</span><span style="color:#89DDFF;">(</span><span style="color:#F07178;font-style:italic;">self</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;font-style:italic;">return</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">len</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;">self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">texts</span><span style="color:#89DDFF;">)</span></span></code></pre></div><h3 id="构造模型" tabindex="-1"><strong>构造模型</strong> <a class="header-anchor" href="#构造模型" aria-label="Permalink to &quot;**构造模型**&quot;">​</a></h3><ul><li>接下来就是如何搭建模型，这里使用 LSTM 做实例，大家也可以尽情尝试其他模型</li><li>❗<strong>请一定保证你使用的模型是你会的，比如如果你用了 LSTM，那么我们则会在面试时抽查 LSTM 相关的知识</strong>❗</li><li>文本任务都会涉及到 embedding，其本质是存储了一个向量矩阵，该矩阵<code>shape=(vocab_size, embedding_dim)</code>，在前向传播时，会将每个词都映射为一个 embedding_dim 维的向量</li></ul><div class="language-Python"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#C792EA;">class</span><span style="color:#A6ACCD;"> </span><span style="color:#FFCB6B;">LSTMModel</span><span style="color:#89DDFF;">(</span><span style="color:#FFCB6B;">torch</span><span style="color:#89DDFF;">.</span><span style="color:#FFCB6B;">nn</span><span style="color:#89DDFF;">.</span><span style="color:#FFCB6B;">Module</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">__init__</span><span style="color:#89DDFF;">(</span><span style="color:#F07178;font-style:italic;">self</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">vocab_size</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">embedding_dim</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">hidden_dim</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">num_layers</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">dropout</span><span style="color:#89DDFF;">=</span><span style="color:#F78C6C;">0.1</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#FFCB6B;">super</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">LSTMModel</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;">self</span><span style="color:#89DDFF;">).</span><span style="color:#82AAFF;">__init__</span><span style="color:#89DDFF;">()</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;font-style:italic;"># embedding是将某个词对应的id映射到向量，然后用这个向量作为模型的输入，该向量的维度为embedding_dim</span></span>
<span class="line"><span style="color:#A6ACCD;">        self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">embedding</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> torch</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">nn</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">Embedding</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">vocab_size</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> embedding_dim</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;font-style:italic;"># 这里用的LSTM模型，也可以尝试其他模型</span></span>
<span class="line"><span style="color:#A6ACCD;">        self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">LSTM</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> torch</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">nn</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">LSTM</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">embedding_dim</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> hidden_dim</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">num_layers</span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;">num_layers</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">batch_first</span><span style="color:#89DDFF;">=True)</span></span>
<span class="line"><span style="color:#A6ACCD;">        self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">classifier</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> torch</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">nn</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">Sequential</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">            torch</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">nn</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">Dropout</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">dropout</span><span style="color:#89DDFF;">),</span></span>
<span class="line"><span style="color:#82AAFF;">            torch</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">nn</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">Linear</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">hidden_dim</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">2</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">forward</span><span style="color:#89DDFF;">(</span><span style="color:#F07178;font-style:italic;">self</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">inputs</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;font-style:italic;"># 最开始的输入inputs.shape = (batch_size, seq_len)</span></span>
<span class="line"><span style="color:#A6ACCD;">        inputs </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> self</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">embedding</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">inputs</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;font-style:italic;"># 过了self.embdding之后，inputs.shape = (batch_size, seq_len, embedding_dim)</span></span>
<span class="line"><span style="color:#A6ACCD;">        x</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> _ </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> self</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">LSTM</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">inputs</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;font-style:italic;"># x.shape = (batch_size, seq_len, hidden_size)</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;font-style:italic;"># 取用 LSTM 最后一个的 hidden state</span></span>
<span class="line"><span style="color:#A6ACCD;">        x </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> x</span><span style="color:#89DDFF;">[:,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">-</span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">:]</span></span>
<span class="line"><span style="color:#A6ACCD;">        x </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> self</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">classifier</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">x</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;font-style:italic;">return</span><span style="color:#A6ACCD;"> x</span></span></code></pre></div><h3 id="训练模型" tabindex="-1"><strong>训练模型</strong> <a class="header-anchor" href="#训练模型" aria-label="Permalink to &quot;**训练模型**&quot;">​</a></h3><ul><li>首先定义需要的组件，这里损失采用交叉熵损失，优化器采用 Adam</li></ul><div class="language-Python"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#A6ACCD;">model </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">LSTMModel</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">vocab_size</span><span style="color:#89DDFF;">=</span><span style="color:#F78C6C;">30000</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;">   </span><span style="color:#676E95;font-style:italic;"># vocab_size为词表大小</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">embedding_dim</span><span style="color:#89DDFF;">=</span><span style="color:#F78C6C;">300</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">hidden_dim</span><span style="color:#89DDFF;">=</span><span style="color:#F78C6C;">256</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">num_layers</span><span style="color:#89DDFF;">=</span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#A6ACCD;font-style:italic;">dropout</span><span style="color:#89DDFF;">=</span><span style="color:#F78C6C;">0.1</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#89DDFF;">).</span><span style="color:#82AAFF;">cuda</span><span style="color:#89DDFF;">()</span><span style="color:#A6ACCD;">    </span><span style="color:#676E95;font-style:italic;"># 将模型移入GPU，只有用GPU时才需要.cuda()</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 定义损失函数和优化器</span></span>
<span class="line"><span style="color:#A6ACCD;">criterion </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> torch</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">nn</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">CrossEntropyLoss</span><span style="color:#89DDFF;">()</span></span>
<span class="line"><span style="color:#A6ACCD;">optimizer </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> torch</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">optim</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">Adam</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">parameters</span><span style="color:#89DDFF;">(),</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">lr</span><span style="color:#89DDFF;">=</span><span style="color:#F78C6C;">0.001</span><span style="color:#89DDFF;">)</span></span></code></pre></div><ul><li>接下来就是如何读取数据，并组成 batch 的数据，需要用到上文的<code>CustomDataset()</code></li></ul><div class="language-Python"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#A6ACCD;">train_dataset </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">CustomDataset</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">texts_train</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> labels_train</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">train_loader </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> torch</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">utils</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">data</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">DataLoader</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;font-style:italic;">dataset</span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;">train_dataset</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">     </span><span style="color:#A6ACCD;font-style:italic;">batch_size</span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;">batch_size</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">shuffle</span><span style="color:#89DDFF;">=True)</span></span></code></pre></div><ul><li>然后就可以开始训练了</li></ul><div class="language-Python"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#89DDFF;font-style:italic;">for</span><span style="color:#A6ACCD;"> epoch </span><span style="color:#89DDFF;font-style:italic;">in</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">range</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">num_epochs</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;font-style:italic;">for</span><span style="color:#A6ACCD;"> inputs</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> labels </span><span style="color:#89DDFF;font-style:italic;">in</span><span style="color:#A6ACCD;"> train_loader</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;font-style:italic;"># 将tensor移入GPU</span></span>
<span class="line"><span style="color:#A6ACCD;">        inputs </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> inputs</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">cuda</span><span style="color:#89DDFF;">()</span></span>
<span class="line"><span style="color:#A6ACCD;">        labels </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> labels</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">cuda</span><span style="color:#89DDFF;">()</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span></span>
<span class="line"><span style="color:#A6ACCD;">        optimizer</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">zero_grad</span><span style="color:#89DDFF;">()</span><span style="color:#A6ACCD;">   </span><span style="color:#676E95;font-style:italic;"># 将上一次迭代的梯度清凉</span></span>
<span class="line"><span style="color:#A6ACCD;">        outputs </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">model</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">inputs</span><span style="color:#89DDFF;">)</span><span style="color:#A6ACCD;">   </span><span style="color:#676E95;font-style:italic;"># 前向传播</span></span>
<span class="line"><span style="color:#A6ACCD;">        loss </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">criterion</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">outputs</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> labels</span><span style="color:#89DDFF;">)</span><span style="color:#A6ACCD;">   </span><span style="color:#676E95;font-style:italic;"># 计算损失</span></span>
<span class="line"><span style="color:#A6ACCD;">        loss</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">backward</span><span style="color:#89DDFF;">()</span><span style="color:#A6ACCD;">    </span><span style="color:#676E95;font-style:italic;"># 反向传播，获得梯度</span></span>
<span class="line"><span style="color:#A6ACCD;">        optimizer</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">step</span><span style="color:#89DDFF;">()</span><span style="color:#A6ACCD;">    </span><span style="color:#676E95;font-style:italic;"># 通过梯度，进行参数更新</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 训练完毕，保存模型</span></span>
<span class="line"><span style="color:#A6ACCD;">torch</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">save</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">model</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">./model.pt</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span></code></pre></div><h3 id="评估模型" tabindex="-1"><strong>评估模型</strong> <a class="header-anchor" href="#评估模型" aria-label="Permalink to &quot;**评估模型**&quot;">​</a></h3><ul><li>评估模型，我们还需要划分出一个验证/测试集，并且同样建立<code>DataLoader()</code>，假设为<code>val_loader</code></li></ul><div class="language-Python"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#676E95;font-style:italic;"># 加载模型</span></span>
<span class="line"><span style="color:#A6ACCD;">model </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> torch</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">load</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">./model.pt</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">for</span><span style="color:#A6ACCD;"> inputs</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> labels </span><span style="color:#89DDFF;font-style:italic;">in</span><span style="color:#A6ACCD;"> val_loader</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">    outputs </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">model</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">inputs</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#676E95;font-style:italic;"># 现在的outputs为一个batch的logits，并且shape=(batch_size, 2)</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#676E95;font-style:italic;"># 请你通过这个outputs矩阵，结合你所挑选的模型评估指标（如准确率），对模型进行评估</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#676E95;font-style:italic;"># 请自行实现</span></span></code></pre></div><p><strong>注意</strong>，<strong>上述均只是一个示例，实际在完成本题过程中，需要根据具体任务和数据进行相应的调整和修改。</strong></p><h2 id="思考" tabindex="-1">思考 <a class="header-anchor" href="#思考" aria-label="Permalink to &quot;思考&quot;">​</a></h2><ol><li>你使用的是什么损失函数？请简单介绍这个损失函数，如果有概率论基础并了解最大似然的同学，请尝试推导出损失函数的数学形式。</li><li>在文本分类任务中可能会面临过拟合问题，尤其是当训练数据较少时，可以采用哪些常见的防止过拟合的方法。</li><li>反向传播是一种用于训练神经网络模型的算法，通过计算损失函数对模型参数的梯度，然后利用梯度下降法更新模型参数。请思考并简单推导一下<strong>你所用的这个模型的</strong>反向传播公式。</li><li>在 LSTM 中，输入门、遗忘门和输出门是如何实现其功能的。</li></ol><h2 id="回答要求" tabindex="-1">回答要求 <a class="header-anchor" href="#回答要求" aria-label="Permalink to &quot;回答要求&quot;">​</a></h2><ol><li>处理数据、训练和测试的代码，并大致解释你的代码；</li><li>代码运行结果截图和训练过程中，损失和<strong>评估指标</strong>（<strong>评估指标不限，如准确率</strong>）的变化图像，并在最后使用你所划分的测试集和你选择的评估指标评估模型结果；</li><li>必要的注释说明及良好的代码规范；</li><li>实现思路和学到的知识点。</li></ol><h2 id="本题提交方式" tabindex="-1">本题提交方式 <a class="header-anchor" href="#本题提交方式" aria-label="Permalink to &quot;本题提交方式&quot;">​</a></h2><blockquote><p>收件邮箱：glimmer401@outlook.com</p><p>主题格式：学号-姓名-考核-机器学习-03</p><p>主题示例：2023091202014-张三-考核-机器学习-03</p></blockquote><blockquote><p>出题人QQ：674940575</p><p>出题人邮箱：<a href="mailto:674940575@qq.com" target="_blank" rel="noreferrer">674940575@qq.com</a></p></blockquote>`,52),t=[p];function e(c,r,y,F,D,i){return n(),a("div",null,t)}const d=s(o,[["render",e]]);export{C as __pageData,d as default};
